{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we take dataframe and split workplaces into smaller compartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "from geopy.distance import great_circle\n",
    "import time as time\n",
    "import random\n",
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0    sp_id  sp_hh_id  age sex  race  relate  school_id  work_id\n",
      "0           0   599955         1    8   F     1       0         48       -1\n",
      "1           1   790949         1   35   F     1       0         -1      173\n",
      "2           2  1094293         1   69   F     1       0         -1       -1\n",
      "3           3   556704         1    2   F     1       0         -1       -1\n",
      "4           4   293648         1   39   M     1       0         -1      182\n",
      "Total number of people in population: 1189525\n",
      "   sp_id   latitude  longitude  size\n",
      "0    1.0  55.186586  61.597408  25.0\n",
      "1    2.0  55.159652  61.570179  31.0\n",
      "2    3.0  55.177610  61.570179  41.0\n",
      "3    4.0  55.195560  61.570179  41.0\n",
      "4    5.0  55.213502  61.570179  28.0\n",
      "Total number of workplaces in population 184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 48,  -1,  44,  79,  99,  14,  52,  43, 105,  60, 109,   8,  54,\n",
       "       101,  50,  64,  89,  59,  78,  84,  26,  61,  73,  96,  27,  95,\n",
       "        51,  46,  69, 104,  40,  11,   2, 106,  72,  16,  80, 108,  17,\n",
       "        20,  41,  82,  77,  67,   7, 107, 103,  30,  28,  42,  88,  25,\n",
       "        83,  85,   5, 110,  65,   4,  49,  63,  32,  35,  53, 102,   9,\n",
       "        29,  21,  37,  12,  62,  34,  75,  98,  90,  91,  13,  81,  10,\n",
       "        24,  22,  92,  68,  87,  23,  39,   1, 100,  31,  18,  45, 111,\n",
       "        86,  57,  58,  74,   6,  36,  15,  66,  97,   3,  56,  93,  71,\n",
       "        47,  76,  33,  19,  94,  55,  38,  70])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_name = 'chelyabinsk'\n",
    "\n",
    "input_path_people = '../data/initial_' + city_name + '/people_' + city_name + '_assigned_schools.txt'\n",
    "input_path_workplaces = '../data/initial_' + city_name + '/workplaces_' + city_name + '.txt'\n",
    "\n",
    "people = pd.read_csv(input_path_people, sep='\\t', index_col=0)\n",
    "workplaces = pd.read_csv(input_path_workplaces, sep='\\t')\n",
    "\n",
    "\n",
    "people['school_id'] = people['school_id'].str.replace('X','-1')\n",
    "people['school_id'] = people['school_id'].astype(str).astype(float).astype(int)\n",
    "\n",
    "people['work_id'] = people['work_id'].str.replace('X','-1')\n",
    "people['work_id'] = people['work_id'].astype(str).astype(float).astype(int)\n",
    "\n",
    "print(people.head())\n",
    "print(\"Total number of people in population:\", len(people['sp_id'].unique()))\n",
    "print(workplaces.head())\n",
    "print(\"Total number of workplaces in population\", len(workplaces))\n",
    "people['school_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551970 637555\n"
     ]
    }
   ],
   "source": [
    "def generate_distribution_data(sum, num_of_samples):\n",
    "    data = []\n",
    "    n_i = num_of_samples\n",
    "    y_i = sum\n",
    "    for i in range(num_of_samples):\n",
    "        x_i = binom.rvs(y_i, 1/n_i, size=1)[0]\n",
    "        data.append(x_i)\n",
    "        y_i = y_i - x_i\n",
    "        n_i = n_i - 1\n",
    "    return data\n",
    "\n",
    "work_id_old = people['work_id'].unique()\n",
    "work_id_old = work_id_old\n",
    "work_id_old = [int(float(elem)) for elem in work_id_old]\n",
    "people_splitted = pd.DataFrame(columns=['sp_id', 'sp_hh_id', 'age',\t'sex',\t'race',\t'relate', 'school_id', 'work_id'])\n",
    "workplaces_splitted = pd.DataFrame(columns=['sp_id', 'latitude', 'longitude', 'size'])\n",
    "work_id_max = 1\n",
    "\n",
    "people_list = []\n",
    "\n",
    "work_id_list = []\n",
    "work_latitude_list = []\n",
    "work_longitude_list = []\n",
    "work_size_list = []\n",
    "\n",
    "people_whole = people.copy()\n",
    "people = people_whole[people['work_id'] > 0]\n",
    "people_without_workplace = people_whole[people_whole['work_id'] < 0]\n",
    "print(len(people_without_workplace), len(people))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/185 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34624/2921711358.py:30: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  work_latitude_list.append(float(workplaces[workplaces['sp_id'] == work_id].latitude))\n",
      "/tmp/ipykernel_34624/2921711358.py:31: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  work_longitude_list.append(float(workplaces[workplaces['sp_id'] == work_id].longitude))\n",
      "100%|█████████████████████████████████████████| 185/185 [04:33<00:00,  1.48s/it]\n",
      "/tmp/ipykernel_34624/2921711358.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  people_splitted['work_id'] = work_id_list\n"
     ]
    }
   ],
   "source": [
    "for work_id in tqdm(work_id_old):\n",
    "    if (work_id == -1):\n",
    "        people_in_current_workplace = people[people['work_id'] == work_id]\n",
    "        print(len(people_in_current_workplace))\n",
    "        people_list.extend(list(people_in_current_workplace['sp_id']))\n",
    "        for i in range(len(people_in_current_workplace)):\n",
    "            work_id_list.append(-1)\n",
    "    else:   \n",
    "        people_in_current_workplace = people[people['work_id'] == work_id]\n",
    "        people_list.extend(list(people_in_current_workplace['sp_id']))\n",
    "        # print(list(people_in_current_dwelling['sp_id']))\n",
    "        number_of_people_in_workplace = len(people_in_current_workplace)\n",
    "        # print(people_list)\n",
    "        \n",
    "        \n",
    "        if (number_of_people_in_workplace < 10):\n",
    "            distribution_for_new_work_id = [number_of_people_in_workplace]\n",
    "        else:\n",
    "            distribution_for_new_work_id = generate_distribution_data(number_of_people_in_workplace, int(number_of_people_in_workplace/8.5))\n",
    "        \n",
    "        # distribution_for_new_hh_id = np.random.poisson(2.5, number_of_people_in_dwelling) \n",
    "        # print(number_of_people_in_workplace, sum(distribution_for_new_work_id))\n",
    "        if (number_of_people_in_workplace != sum(distribution_for_new_work_id)):\n",
    "            raise RuntimeError(\"Mismatch\")\n",
    "        \n",
    "        for people_in_work_id in distribution_for_new_work_id:\n",
    "            for i in range(people_in_work_id):\n",
    "                work_id_list.append(work_id_max)\n",
    "                work_size_list.append(people_in_work_id)\n",
    "                work_latitude_list.append(float(workplaces[workplaces['sp_id'] == work_id].latitude))\n",
    "                work_longitude_list.append(float(workplaces[workplaces['sp_id'] == work_id].longitude))\n",
    "            work_id_max+=1\n",
    "\n",
    "people_splitted = people\n",
    "people_splitted['work_id'] = work_id_list\n",
    "workplaces_splitted['sp_id'] = work_id_list\n",
    "workplaces_splitted['size'] = work_size_list\n",
    "workplaces_splitted['latitude'] = work_latitude_list\n",
    "workplaces_splitted['longitude'] = work_longitude_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_splitted = pd.concat([people_splitted, people_without_workplace])\n",
    "\n",
    "people_splitted.to_csv('../data/initial_' + city_name + '/people_' + city_name + '_splitted_workplaces.txt', sep='\\t')\n",
    "workplaces_splitted.to_csv('../data/initial_' + city_name + '/workplaces_' + city_name + '_splitted.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,  48,  44,  79,  99,  14,  52,  43, 105,  60, 109,   8,  54,\n",
       "       101,  50,  64,  89,  59,  78,  84,  26,  61,  73,  96,  27,  95,\n",
       "        51,  46,  69, 104,  40,  11,   2, 106,  72,  16,  80, 108,  17,\n",
       "        20,  41,  82,  77,  67,   7, 107, 103,  30,  28,  42,  88,  25,\n",
       "        83,  85,   5, 110,  65,   4,  49,  63,  32,  35,  53, 102,   9,\n",
       "        29,  21,  37,  12,  62,  34,  75,  98,  90,  91,  13,  81,  10,\n",
       "        24,  22,  92,  68,  87,  23,  39,   1, 100,  31,  18,  45, 111,\n",
       "        86,  57,  58,  74,   6,  36,  15,  66,  97,   3,  56,  93,  71,\n",
       "        47,  76,  33,  19,  94,  55,  38,  70])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_splitted['school_id'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
